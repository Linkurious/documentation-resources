# User-Data Store Migration Tool

## Context
Linkurious Enterprise is shipped with an embedded SQLite database
to allow an immediate usage of the system in a Proof of Concept (PoC) environment, however it is a best practice to rely on a Relational Databased Management System (RDBMS) in a production environment.

It is a common need of our customers to migrate the data from the SQLite database to an external relational database.

Since different databases may use different syntax, this tools is aimed to provide the most reliable process to safely migrate the data.

> /!\ The tool's objective is to migrate data from SQLite to an external database for the same Linkurious Enterprise instance. No other scenarios are covered.


## The migration process

Linkurious Enterprise is designed to create and maintain (through the updates) its data structure over the supported databases.

The safest migration approach is to let the system handle the whole task of defining the database schema and then perform manual tasks only to reimport the data.

The tool is designed to help a database administrator generate the correct script to import data starting from a dump. In particular the script will:
1. remove all the `DDL` instructions;
2. change all the `insert` instructions to explicitly add the field name (to ensure the correct mapping of data regardless possible difference in the order);
3. `Truncate` all the table's contents before data insert (it is needed to delete any default data generated by the system during the schema creation);
4. correct any known compatibility issue between the output syntax of sqlite3 dump and the syntax used by the supported databases;
5. list in output all the `select` instructions needed to access all the migrated data, it could be useful for running any query to verify the correctness of the migration.


## How to use the tool

1. Create a text dump of the current SQLite file with the sqlite3 tool:
   ```shell
   sqlite3 ./linkurious/data/server/database.sqlite .dump > export.sql
   ```

   The tool has been tested to support also migration from MySQL (see the section [How to migrate from MySQL](#how-to-migrate-from-mysql)).

   > /!\ Minimum requirement sqlite3 v3.19.0. Earlier versions will not export properly multiline data (e.g. queries or descriptions containing multiple lines)

2. Put the `export.sql` file in the same directory of the `dump-converter.py` python script
3. Run the program to generate a new SQL import script:
   
   example for MySQL
   ```shell
   python3 dump-converter.py --dialect mysql -d schema.json -o export-parsed.sql export.sql > select-queries.sql
   ```
   example for MariaDB
   ```shell
   python3 dump-converter.py --dialect mariadb -d schema.json -o export-parsed.sql export.sql > select-queries.sql
   ```
   example for Microsoft SQL Server
   ```shell
   python3 dump-converter.py --dialect mssql -d schema.json -o export-parsed.sql export.sql > select-queries.sql
   ```
4. The program will generate three files:
   - `export-parsed.sql` : the new SQL import file to be used instead of the initial one
   - `select-queries.sql` : a script containing the `select` queries for all the tables found in the initial script. It can be useful for debugging / crosscheck purposes.
   - `schema.json` : the schema discovered in the input script, useful to resolve eventual schema conflicts (see later for more details)
5. Setup your external database server and create an empty database
6. Configure Linkurious Enterprise to point the new Database (refer to the correct version of the [documentation](https://doc.linkurio.us) in case of doubts)
7. Start Linkurious Enterprise
8. As soon as it starts properly (you can see the application, regardless the connection error to the graph database), stop it.
9. Run the new script in your system to import data (since the system uses **unicode characters**, be careful to the encoding):
   
   example for MySQL
   ```shell
   mysql -u MY_MYSQL_USER -p -h 127.0.0.1 --default-character-set=utf8mb4 linkurious < export-parsed.sql
   ```
   example for MariaDB
   ```shell
   mariadb -u MY_MYSQL_USER -p -h 127.0.0.1 --default-character-set=utf8mb4 linkurious < export-parsed.sql
   ```
   example for Microsoft SQL Server
   ```shell
   sqlcmd -U MY_MYSQL_USER -S 127.0.0.1 -d linkurious -i export-parsed.sql
   ```

   > /!\ In case you get errors related to the schema definition, see the section [How to manage schema conflicts](#how-to-handle-schema-conflicts)

10. After the import script is executed successfully you can start again Linkurious Enterprise and accessing all the previous data


## How to handle schema conflicts
Depending on the configuration and the sequence of updates performed in the system,
it may happen that the old database has a different schema compared to the new fresh installation.
Main possibility is that the old schema contains some obsolete columns that have not been created in the fresh installation.

To fix this problem, it is possible to execute again the tool with providing the new correct schema.
1. Following the standard procedure, tanks to the option `-d schema.json`,
the tool has already generated a `schema.json` file containing the structure identified in the `*.sql` file
1. Change the file to remove the extra columns based on import failures
1. Execute again the tool specifying the new schema with option `--schema`
   
   example for MySQL
   ```shell
   python3 dump-converter.py --dialect mysql --schema schema.json -o export-parsed.sql export.sql > select-queries.sql
   ```
   example for MariaDB
   ```shell
   python3 dump-converter.py --dialect mariadb --schema schema.json -o export-parsed.sql export.sql > select-queries.sql
   ```
   example for Microsoft SQL Server
   ```shell
   python3 dump-converter.py --dialect mssql --schema schema.json -o export-parsed.sql export.sql > select-queries.sql
   ```

Repeat the above steps as many time as required to to fix all the mismatch.


## How to migrate from MySQL
In case of migration from MySQL server instead of Sqlite, use the following procedure to create the `export.sql` file.

1. Add the `lke_export` stored procedure provided in the `mysql_export_sp.sql` script
   ```shell
   mysql -u MY_MYSQL_USER -p -h 127.0.0.1 linkurious < mysql_export_sp.sql
   ```
1. Execute the store procedure, note the presence of `-NBr` parameters (mandatory to avoid format issues)
   ```shell
   mysql -NBr -u MY_MYSQL_USER -p -h 127.0.0.1 --default-character-set=utf8mb4 -e "call lke_export" linkurious > export.sql
   ```

Follow the rest of the standard procedure for Sqlite migration.


## How to customize the tool

The script is developed to work without any change based on the current known issues at the time of the development.
Some parameters are available to configure the destination database or the input / output file, below the extract of the help.

```shell
$ python3 dump-converter.py --help
usage: python3 dump-converter.py [options] INPUT > select-queries.sql

Linkurious Enterprise User-Data Store dump converter

positional arguments:
  INPUT                 the SQLite dump to convert (a *.sql file)

optional arguments:
  -h, --help            show this help message and exit
  -o OUTPUT, --out OUTPUT
                        the output file for the new import instructions
                        (default: export-parsed.sql)
  -d DUMP_SCHEMA, --dump-schema DUMP_SCHEMA
                        the output file in json format of the schema used to
                        create the output, compatible with the schema option
                        (default: not exported)
  --dialect {mysql,mariadb,mssql}
                        the dialect of the destination database (default:
                        mysql)
  --schema SCHEMA       the file containing the destination schema structure,
                        it is a *.json file containing the mapping as { "table
                        name": ["list of columns"] } (default: everything is
                        created according to the input file)
```

However it is possible to quickly modify the tool to change / add conversion rules to adapt it to your needs.

The tool relies on the below global variables to create the output file:
- `pre`: an array of strings (instructions) to add at the beginning of the output file.
- `replace_rules`: an array of `conversion rules` to apply to each input line. The rules are tried in order of definition. Each rule is a record of 6 elements:
  - A `boolean` indicating whether the second parameter is a regex expression or not (just a single replace).
  - A `string` with the `match rule`. In case of regex, it is possible to define groups to be used in the replace string.
  - A `string` with the `replace string`. In case of regex, it is possible to define placeholders to be replaced with value matched in the groups (`{i}` where `i` is the group index).
  - A `number` with the number of defined groups that will be replace in the `replace string`
  - A function (used only with regex rules) getting as parameters the `regex match` and the current `replace string`. It has to return a `string` with the new `replace string`.
  - A `boolean` indicating whether the system should stop or not to test the other rules when the current rule is matched.
- `post`: an array of strings (instructions) to add at the end of the output file.
